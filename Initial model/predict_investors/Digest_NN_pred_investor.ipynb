{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50b94e12-9412-4415-b6ac-2aba9bf6f83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b24e7f-1637-4a29-a362-cfa0e3b13c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import sklearn as sk\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sn\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.metrics import r2_score, explained_variance_score, confusion_matrix, accuracy_score, classification_report, log_loss\n",
    "from math import sqrt\n",
    "\n",
    "# Creating the modeling dataset\n",
    "# from sklearn.datasets import make_classification\n",
    "# Data processing\n",
    "\n",
    "# Model and performance\n",
    "#from sklearn.model_selection import train_test_split\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# Oversampling and under sampling\n",
    "# from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "# from imblearn.under_sampling import RandomUnderSampler, NearMiss\n",
    "# from collections import Counter\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c85a9fa-1d5b-4ac3-b445-1ea578553da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load and preprocess the data\n",
    "# data = pd.read_csv(\"startup_funding.csv\")\n",
    "# X = data.iloc[:, 0:10].values\n",
    "# y = data.iloc[:, 10:].values\n",
    "\n",
    "# Define the neural network architecture\n",
    "# model = Sequential()\n",
    "# model.add(Dense(64, input_dim=10, activation='relu'))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dense(16, activation='relu'))\n",
    "# model.add(Dense(8, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "# model.fit(X, y, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Generate predictions for a new startup\n",
    "# new_startup = np.array([[1000000, 0, 1, 0, 0, 0, 1, 0, 0, 0]])\n",
    "# predictions = model.predict(new_startup)\n",
    "\n",
    "# Select the output nodes with the highest activation levels\n",
    "# investors = np.argsort(predictions)[0][-15:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ee06df-118b-475a-804a-b175d8a4d291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the data\n",
    "# data = pd.read_csv(\"startup_funding.csv\")\n",
    "# X = data.iloc[:, 0:10].values\n",
    "# investor_names = data.columns[10:].tolist()\n",
    "# y = data.iloc[:, 10:].values\n",
    "\n",
    "# Define the neural network architecture\n",
    "# model = Sequential()\n",
    "# model.add(Dense(64, input_dim=10, activation='relu'))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dense(16, activation='relu'))\n",
    "# model.add(Dense(len(investor_names), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "# model.fit(X, y, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Generate predictions for a new startup\n",
    "# new_startup = np.array([[1000000, 0, 1, 0, 0, 0, 1, 0, 0, 0]])\n",
    "# predictions = model.predict(new_startup)\n",
    "\n",
    "# Map the numeric output to investor names\n",
    "# investor_probs = {name: prob for name, prob in zip(investor_names, predictions[0])}\n",
    "# top_investors = sorted(investor_probs, key=investor_probs.get, reverse=True)[:15]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0174914-3559-497e-82a0-81e7620b65c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deals = pd.read_excel ('../data/Deals (investment).xlsx')\n",
    "df_deals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce77a173-5b85-490a-8313-7b7d638646f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df_deals.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5013b1-ffa5-45d5-af8a-dd926e52fc76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for cat_col in cols:\n",
    "    print(f\"{cat_col}: {df_deals[cat_col].nunique()} uniqueness variable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d7b8cf-ea55-4a8e-8500-1edd5b77ffbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a2a1ee-ede1-4961-a43b-80fb862b77e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_deals['Investor 2'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257e5bcb-b7d5-496c-b4e9-b0e9d1e0b6f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_deals.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203263a8-cfdf-463f-b9af-61119e6b72f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deals = df_deals.drop(['Investor 1','Cummulative Deals (Disclosed)','Cummulative Deals (Undisclosed)','Cummulative Amount','7_source','4_Stake','Investor 2', 'Investor 3',\n",
    "       'Investor 4', 'Investor 5', 'Investor 6', 'Investor 7', 'Investor 8',\n",
    "       'Investor 9', 'Investor 10', 'Investor 11', 'Investor 12','Investor 13','Investor 14','Investor 13.1','Investor 14.1','Investor 15.1','Investor 15','Duplication','Investor 1.1',\n",
    "       'Investor 2.1', 'Investor 3.1', 'Investor 4.1', 'Investor 5.1',\n",
    "       'Investor 6.1', 'Investor 7.1', 'Investor 8.1', 'Investor 9.1',\n",
    "       'Investor 10.1', 'Investor 11.1', 'Investor 12.1'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7205a45f-bc8a-4e3f-8829-77beabd31928",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac109b8-68db-4038-b0f0-413dffabb109",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_deals[\"DA Classification_African Company (Yes = 0; No = 1)\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106b4d5d-a851-4cc3-a0a0-daf63fc8d12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deals = df_deals.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9830d6-04cb-428a-9cde-dc11768d7a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_deals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb80495-7ae7-41ff-a14a-75baeb930428",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b42581-5f15-498a-934e-d31747c04bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_year(dt):\n",
    "    return dt.year\n",
    "\n",
    "df_deals['year'] = df_deals['1_post_date'].map(get_year)\n",
    "#df_deals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f21e58-8a74-4f65-8d7a-3038785b5ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_deals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2a88fe-d974-4f92-bb25-cba0d2f61d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deals = df_deals.drop(['Year','year','Country/Town'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79686d6a-0e0a-4a64-a993-92ba70953898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_deals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b8b7fb-23ac-4f08-a65a-9004853775be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping columns that the startup wont have prior\n",
    "df_deals = df_deals.drop(['1_post_date','2_post_title','Check vs Companies','Industry, DA'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901b94b6-9d60-43bd-bbbf-59c327158c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_deals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faf4d21-a2c5-472d-82e3-c3f43179292b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deals = df_deals.drop(['duplicated_conc'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454a3500-0f75-497e-9266-d0268a1c3556",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deals['5_funding_round'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2d9092-7240-48cc-a3ec-f51f03519ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49191374-9d2e-452e-a742-879a1a348a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55effda-d254-492c-b038-29fc9220cdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_deals['main_sector'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4105a9e8-5136-4322-b0bf-9a895aca7873",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deals['main_sector'] = df_deals['main_sector'].apply(lambda x: x.lower())\n",
    "df_deals['main_sector'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f79ba9-e1a8-48f8-abbc-46096dbf7786",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_sector(sector):\n",
    "    if 'recruitment' in sector.lower():\n",
    "        return 'recruitment, human resource'\n",
    "    elif 'media/ entertainment' in sector.lower():\n",
    "        return 'media and entertainment'\n",
    "    elif 'media & entertainment' in sector.lower():\n",
    "        return 'media and entertainment'\n",
    "    elif 'solar power' in sector.lower():\n",
    "        return 'solar energy, energy and resources'\n",
    "    elif 'real estate' in sector.lower():\n",
    "        return 'real estate and construction'\n",
    "    elif 'resource & energy' in sector.lower():\n",
    "        return 'solar energy, energy and resources'\n",
    "    elif 'telecommunications' in sector.lower():\n",
    "        return 'utilities and telecommunication services'\n",
    "    elif 'renewable energy' in sector.lower():\n",
    "        return 'renewables & environment'\n",
    "    elif 'information technology' in sector.lower():\n",
    "        return 'other technologies & information technology'\n",
    "    else:\n",
    "        return sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f79a82-2255-4a3d-a792-718200b47777",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying our function to eliminate duplicates\n",
    "df_deals['main_sector'] = df_deals['main_sector'].apply(main_sector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f527b6-6d69-4916-8970-8d25c5c8a672",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deals['main_sector'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f00f5d-c7a7-4058-8120-c0b428756e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping_ms = [{'col': 'main_sector', 'mapping': {'financial services': 1, 'recruitment, human resource': 2, 'education': 3,\n",
    "#        'media and entertainment': 4, 'e-commerce & retail': 5,\n",
    "#        'other technologies & information technology': 6,\n",
    "#        'real estate and construction': 7,\n",
    "#        'commercial & professional services': 8, 'software': 9,\n",
    "#        'transport & logistics': 10, 'automotive': 11, 'healthcare & pharma': 12,\n",
    "#        'utilities and telecommunication services': 13, 'agriculture': 14,\n",
    "#        'travel & leisure': 15, 'social network': 16, 'security': 17,\n",
    "#        'renewables & environment': 18, 'emerging technologies': 19, 'saas': 20,\n",
    "#        'marketing': 21, 'solar energy, energy and resources': 22, 'robotics': 23,\n",
    "#        'travel and leisure': 24}}]\n",
    "# OrdinalEncoder(cols=['main_sector'], mapping=mapping_ms).fit(df_deals).transform(df_deals)\n",
    "\n",
    "mapping_ms = {'financial services': 1, 'recruitment, human resource': 2, 'education': 3,\n",
    "       'media and entertainment': 4, 'e-commerce & retail': 5,\n",
    "       'other technologies & information technology': 6,\n",
    "       'real estate and construction': 7,\n",
    "       'commercial & professional services': 8, 'software': 9,\n",
    "       'transport & logistics': 10, 'automotive': 11, 'healthcare & pharma': 12,\n",
    "       'utilities and telecommunication services': 13, 'agriculture': 14,\n",
    "       'travel & leisure': 15, 'social network': 16, 'security': 17,\n",
    "       'renewables & environment': 18, 'emerging technologies': 19, 'saas': 20,\n",
    "       'marketing': 21, 'solar energy, energy and resources': 22, 'robotics': 23,\n",
    "       'travel and leisure': 24}\n",
    "\n",
    "df_deals['main_sector_encoded'] = df_deals['main_sector'].apply(lambda x: mapping_ms[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c96fc7-0f8b-4127-8e8d-7395934be43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_deals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4a67cb-066e-4679-a56a-fa8b3e67d084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping_sr = [{'col': '5_funding_round', 'mapping': {'Seed': 1, 'Grant': 2, 'Series A': 3, 'Angel': 4, 'Debt Financing': 5, 'Series B': 6,\n",
    "#        'Series D': 7, 'Series C': 8, 'Private Equity': 9, 'Pre-Series B': 10,\n",
    "#        'Convertible Note': 11, 'Pre-Seed': 12, 'Venture Round': 13, 'Series E': 14,\n",
    "#        'Undisclosed': 15, 'Crowdfunding': 16, 'Corporate Venture': 17,\n",
    "#        'Corporate Round': 18, 'Series A II': 19, 'CrowdFunding': 20}}]\n",
    "# OrdinalEncoder(cols=['5_funding_round'], mapping=mapping_sr).fit(df_deals).transform(df_deals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b868f4d0-a2d2-4bac-88dd-81ebd389c944",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_sr = {'Seed': 1, 'Grant': 2, 'Series A': 3, 'Angel': 4, 'Debt Financing': 5, 'Series B': 6,\n",
    "       'Series D': 7, 'Series C': 8, 'Private Equity': 9, 'Pre-Series B': 10,\n",
    "       'Convertible Note': 11, 'Pre-Seed': 12, 'Venture Round': 13, 'Series E': 14,\n",
    "       'Undisclosed': 15, 'Crowdfunding': 16, 'Corporate Venture': 17,\n",
    "       'Corporate Round': 18, 'Series A II': 19, 'CrowdFunding': 20}\n",
    "\n",
    "df_deals['funding_round_encoded'] = df_deals['5_funding_round'].apply(lambda x: mapping_sr[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a10be18-96f0-4eff-95fd-2b674f93689f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7764af-347c-4ea9-8a82-97826e7cb660",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_deals['Category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49c4c25-d179-433e-8822-cc4f7b63ffe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54748fef-3209-4607-92d0-6132263d2543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the data\n",
    "data = df_deals\n",
    "X = data.iloc[:, 0:2].values\n",
    "# Y_train_label = train.Activity.values.astype(object)\n",
    "# investor_names = data.columns[10:].tolist()\n",
    "y = data.iloc[:, 2:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd2aa9a-e48f-4c59-96e2-df5ed11ec422",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.rename(columns={' Disclosed': \"Disclosed\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66694f1-7735-466b-bafb-46c0889b4813",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_value = data['6_investors'].mode()[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb224390-0c48-4197-9aaa-98e18e9263c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['6_investors'].fillna(mode_value, inplace=True)\n",
    "# data['6_investors'] = data['6_investors'].replace('Undisclosed', mode_value, inplace=True)\n",
    "\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c427660-03a8-4e34-b75d-a9ab3f6c71e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the funding total column is read as a object so clearning it up so that we can use it as a numerical column\n",
    "data['5_funding_round']=data['5_funding_round'].str.replace(',','') # removing commas from funding_total_usd column\n",
    "data['5_funding_round']=data['5_funding_round'].str.replace(' ','')#removing extra space from funding_total_usd column\n",
    "# df['funding_total_usd']=df['funding_total_usd'].str.replace('-','0')\n",
    "#removing - from funding_total_usd column and replacing with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4885f83-dbde-4f42-8a3b-64fb8d058891",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['5_funding_round'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d332d5e-af42-46fc-8cb7-8aabb9059224",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['Category','funding round, DA'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea565aea-dd13-4ac7-adf6-635959ddb321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f96cac-5157-4b67-abc9-1c923e51b14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['5_funding_round'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40989af1-2c6c-41c9-90a4-cac5009f49d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['cat_funding_round'] = data['5_funding_round'].replace(['Seed', 'Grant', 'SeriesA', 'Angel', 'DebtFinancing', 'SeriesB',\n",
    "#        'SeriesD', 'SeriesC', 'PrivateEquity', 'Pre-SeriesB',\n",
    "#        'ConvertibleNote', 'Pre-Seed', 'VentureRound', 'SeriesE',\n",
    "#        'Undisclosed', 'Crowdfunding', 'CorporateVenture',\n",
    "#        'CorporateRound', 'SeriesAII', 'CrowdFunding'], [0, 1, 2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8336cce2-f2de-4c3b-8b61-71318ea04ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62373163-b796-4bbe-adb5-f18a3c2b2701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating instance of labelencoder\n",
    "labelencoder = LabelEncoder()\n",
    "#using label encoder for these two columns as there is a lot of variables\n",
    "data['cat_Country'] = labelencoder.fit_transform(data['Country(HQ)']) # using label encoder on continent\n",
    "# data['cat_6_investors'] = labelencoder.fit_transform(data['6_investors']) # using label encoder on industry group\n",
    "# data['cat_main_sector'] = labelencoder.fit_transform(data['main_sector'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd71eef5-8215-48bf-bd17-6bbe21bf3856",
   "metadata": {},
   "source": [
    "### prepare data for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b574c8cc-6d41-4532-9b2d-bc1f4175a83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dba015-3659-4e5e-814c-cb717e885a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data[['Deals Information, Level of Completeness', 'Disclosed ',\n",
    "       'Founded', 'Total  Disclosed Funding',\n",
    "       'DA Classification_African Company (Yes = 0; No = 1)', 'Month',\n",
    "       'Quarter', 'Half', 'Number of Investors', 'main_sector_encoded',\n",
    "       'funding_round_encoded', 'cat_Country']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632f6b96-c583-4b64-bf4e-601c127a7953",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_types(df):\n",
    "    \"\"\"\n",
    "    Get the data types of all columns in a dataframe.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The dataframe to retrieve data types from.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping column names to their respective data types.\n",
    "    \"\"\"\n",
    "    data_types = df.dtypes.to_dict()\n",
    "    return data_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b40dca-316d-4edd-bc0c-7b6a48240455",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_types = get_data_types(data1)\n",
    "\n",
    "# Print the data types\n",
    "print(data_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1eb8b0d-d2f7-4fe8-8c80-e0be210689b1",
   "metadata": {},
   "source": [
    "#### Statitics and correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c3d889-102a-4dd9-93d9-3b4c3f7c5117",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating correlation matrix\n",
    "colormap = plt.cm.viridis\n",
    "plt.figure(figsize = (35, 35))\n",
    "plt.title('Pearson Correlation of features', y = 1.05, size = 15)\n",
    "matrix = np.triu(data1.corr())\n",
    "sns.heatmap(data1.astype(float).corr(), linewidth = 0.1, vmax = 1.0, square =True, cmap=colormap, linecolor = 'white', annot=True, mask = matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c81a7fa-2d64-4e58-8f3f-eecd8a0ca115",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['3_amount','5_funding_round','Country(HQ)','main_sector'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4df9fc-c4e9-432e-af3a-b34b80367158",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bc797a-a1d4-4add-b711-94e7389d3638",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data['6_investors'] #setting Y variable\n",
    "X = data.drop('6_investors', axis = 1) #dropping status and setting features\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 42)#test and train dataset\n",
    "Y_train_label = Y_train.values.astype(object)\n",
    "Y_test_label = Y_test.values.astype(object)\n",
    "# Y_train.shape\n",
    "# X_test.shape\n",
    "# Y_test.shape\n",
    "X_test.head()\n",
    "Y_train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cd6687-93a8-4e88-82a5-dfcccc9b4ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking size of each dataset\n",
    "print('Shape of X_train=>',X_train.shape)\n",
    "print('Shape of X_test=>',X_test.shape)\n",
    "print('Shape of Y_train=>',Y_train.shape)\n",
    "print('Shape of Y_test=>',Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7965335-34c8-4e22-b9ab-0b2ece6ed678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming non numerical labels into numerical labels\n",
    "from sklearn import preprocessing\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "# encoding train labels \n",
    "encoder.fit(Y_train_label)\n",
    "Y_train = encoder.transform(Y_train_label)\n",
    "\n",
    "# encoding test labels \n",
    "encoder.fit(Y_test_label)\n",
    "Y_test = encoder.transform(Y_test_label)\n",
    "\n",
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f939ed34-3e78-4d70-9c94-0fed5d82d804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the Train and Test feature set \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "# X_train.shape\n",
    "# X_train.shape\n",
    "X_test_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13ec8fb-b82d-41aa-a0c9-5511cd7d0388",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries to Build Ensemble Model : Random Forest Classifier \n",
    "# Create the parameter grid based on the results of random search \n",
    "params_grid = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530778d6-1321-4ccd-a712-230a35300c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7f9c37-6468-41ec-ac51-0a4960e274a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing CV to tune parameters for best SVM fit \n",
    "svm_model = GridSearchCV(SVC(), params_grid, cv=5)\n",
    "svm_model.fit(X_train_scaled, Y_train)\n",
    "# Y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e8bef6-f39a-4274-ad3c-f347b5da28a3",
   "metadata": {},
   "source": [
    "#### Confusion Matrix and Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0402581-094d-4776-b3e3-78bcb9ce2fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the accuracy score\n",
    "print('Best score for training data:', svm_model.best_score_,\"\\n\") \n",
    "\n",
    "# View the best parameters for the model found using grid search\n",
    "print('Best C:',svm_model.best_estimator_.C,\"\\n\") \n",
    "print('Best Kernel:',svm_model.best_estimator_.kernel,\"\\n\")\n",
    "print('Best Gamma:',svm_model.best_estimator_.gamma,\"\\n\")\n",
    "\n",
    "final_model = svm_model.best_estimator_\n",
    "Y_pred = final_model.predict(X_test_scaled)\n",
    "# Y_pred\n",
    "Y_pred_label = list(encoder.inverse_transform(Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60f640c-0323-43ab-86b3-9d5147809f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Confusion Matrix\n",
    "#print(pd.crosstab(Y_test_label, Y_pred_label, rownames=['Actual Activity'], colnames=['Predicted Activity']))\n",
    "print(confusion_matrix(Y_test_label,Y_pred_label))\n",
    "print(\"\\n\")\n",
    "print(classification_report(Y_test_label,Y_pred_label))\n",
    "\n",
    "print(\"Training set score for SVM: %f\" % final_model.score(X_train_scaled , Y_train))\n",
    "print(\"Testing  set score for SVM: %f\" % final_model.score(X_test_scaled  , Y_test ))\n",
    "\n",
    "svm_model.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3179af-8cb0-4a88-9157-497cfea6557f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# names_of_predictors = list(X_train.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f999cf9-a277-4176-8473-3c06aa09d59e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# names_of_predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfefbec-cfa9-4fc6-bdbd-1fd55cd5a92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the Train and Test feature set \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2179c4-7d4c-4f1d-b764-bc9c09d51feb",
   "metadata": {},
   "source": [
    "##### Hyperparameter tuning using grid search and cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e655c54-20a4-4029-9246-3299a64e1aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries to Build Ensemble Model : Random Forest Classifier \n",
    "# Create the parameter grid based on the results of random search \n",
    "# params_grid = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "#                      'C': [1, 10, 100, 1000]},\n",
    "#                     {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c9206e-eb0c-4ab6-ac5e-30af8117da31",
   "metadata": {},
   "source": [
    "#### Training SVM model using radial kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9909bd-2f02-49e5-bde0-676fe6da433c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.utils import shuffle\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.metrics import confusion_matrix,classification_report\n",
    "# from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1256ef37-1ef1-452e-8bf3-a210bcaff49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51819b9-81da-4b7d-bc5e-1276a6300af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_train.head()\n",
    "\n",
    "# x = np.asfarray(Y_train)\n",
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a172356-16b7-4b79-b601-c0b7f4b9f2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing CV to tune parameters for best SVM fit \n",
    "# svm_model = GridSearchCV(SVC(), params_grid, cv=5)\n",
    "# svm_model.fit(X_train_scaled, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd59998-41eb-4054-9cb1-88e77175afec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
